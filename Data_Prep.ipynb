{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbelKosh/NeurIPS/blob/main/Data_Prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "OO_eiXSa_a6s",
        "outputId": "533aa066-532e-4dd2-e215-9091b7a8f9ac"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f9a75300-a787-40ee-a4e5-09dbe86b804e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f9a75300-a787-40ee-a4e5-09dbe86b804e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"abelko\",\"key\":\"c02c786c0025632b848596dab1f083a0\"}'}"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()  # This will prompt you to upload the kaggle.json file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-qhJIuT_cij"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json  # Set proper permissions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOdw0w2ZEV2m"
      },
      "source": [
        "## Calibrating and Time Binning Astronomical Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MylT7_CZCa2m",
        "outputId": "1171f059-4378-4e88-822f-d1dbd930b300"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading ariel-data-challenge-2024.zip to /content/drive/MyDrive/ariel-data-challenge-2024\n",
            "100% 160G/160G [2:07:12<00:00, 26.8MB/s]\n",
            "100% 160G/160G [2:07:12<00:00, 22.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c ariel-data-challenge-2024 -p /content/drive/MyDrive/ariel-data-challenge-2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRsJOSK3J9Qz",
        "outputId": "006c28b0-70a5-4781-855d-7dd04a8b3d61",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  inflating: /content/drive/MyDrive/ariel-data-challenge-2024/train/2364740784/FGS1_calibration/dead.parquet  \n",
            "  inflating: /content/drive/MyDrive/ariel-data-challenge-2024/train/2364740784/FGS1_calibration/flat.parquet  \n",
            "  inflating: /content/drive/MyDrive/ariel-data-challenge-2024/train/2364740784/FGS1_calibration/linear_corr.parquet  \n",
            "  inflating: /content/drive/MyDrive/ariel-data-challenge-2024/train/2364740784/FGS1_calibration/read.parquet  \n",
            "  inflating: /content/drive/MyDrive/ariel-data-challenge-2024/train/2364740784/FGS1_signal.parquet  \n",
            "  inflating: /content/drive/MyDrive/ariel-data-challenge-2024/train/2372647732/AIRS-CH0_calibration/dark.parquet  \n",
            "  inflating: /content/drive/MyDrive/ariel-data-challenge-2024/train/2372647732/AIRS-CH0_calibration/dead.parquet  \n",
            "  inflating: /content/drive/MyDrive/ariel-data-challenge-2024/train/2372647732/AIRS-CH0_calibration/flat.parquet  \n",
            "  inflating: /content/drive/MyDrive/ariel-data-challenge-2024/train/2372647732/AIRS-CH0_calibration/linear_corr.parquet  \n",
            "  inflating: /content/drive/MyDrive/ariel-data-challenge-2024/train/2372647732/AIRS-CH0_calibration/read.parquet  \n",
            "  inflating: /content/drive/MyDrive/ariel-data-challenge-2024/train/2372647732/AIRS-CH0_signal.parquet  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/MyDrive/ariel-data-challenge-2024/ariel-data-challenge-2024.zip -d /content/drive/MyDrive/ariel-data-challenge-2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2k6OBJJMhqQ",
        "outputId": "826f4d94-d0a7-493f-97b5-a941b0c1ca57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting astropy\n",
            "  Downloading astropy-6.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from astropy) (1.26.4)\n",
            "Collecting pyerfa>=2.0.1.1 (from astropy)\n",
            "  Downloading pyerfa-2.0.1.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting astropy-iers-data>=0.2024.8.27.10.28.29 (from astropy)\n",
            "  Downloading astropy_iers_data-0.2024.9.23.0.31.43-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: PyYAML>=3.13 in /usr/local/lib/python3.10/dist-packages (from astropy) (6.0.2)\n",
            "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.10/dist-packages (from astropy) (24.1)\n",
            "Downloading astropy-6.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astropy_iers_data-0.2024.9.23.0.31.43-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyerfa-2.0.1.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m738.7/738.7 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyerfa, astropy-iers-data, astropy\n",
            "Successfully installed astropy-6.1.4 astropy-iers-data-0.2024.9.23.0.31.43 pyerfa-2.0.1.4\n"
          ]
        }
      ],
      "source": [
        "!pip install astropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KQ7lljZCglT"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import os\n",
        "import glob\n",
        "import threading\n",
        "from numpy.polynomial import Polynomial\n",
        "from astropy.stats import sigma_clip\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwkSeEzWEwno"
      },
      "outputs": [],
      "source": [
        "# paths to import data and save light version\n",
        "\n",
        "path_folder = '/content/drive/MyDrive/ariel-data-challenge-2024/' # path to the folder containing the data\n",
        "path_out = '/content/tmp/data_light_raw/' # path to the folder to store the light data\n",
        "output_dir = '/content/tmp/data_light_raw/' # path for the output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SruZbTwE73W",
        "outputId": "162e0723-7ed2-4682-9e1f-e301779bfa89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directory /content/tmp/data_light_raw/ created.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(path_out):\n",
        "    os.makedirs(path_out)\n",
        "    print(f\"Directory {path_out} created.\")\n",
        "else:\n",
        "    print(f\"Directory {path_out} already exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQ9qZVnBE7xq"
      },
      "outputs": [],
      "source": [
        "CHUNKS_SIZE = 1 ## for this demo, it must be divisible by 672 (N Training data )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL1Y1rzbFN49"
      },
      "source": [
        "## Step 1: Analog-to-Digital Conversion\n",
        "The Analog-to-Digital Conversion (adc) is performed by the detector to convert the pixel voltage into an integer number. We revert this operation by using the gain and offset for the calibration files 'train_adc_info.csv'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqGbPcEiE7rv"
      },
      "outputs": [],
      "source": [
        "def ADC_convert(signal, gain, offset):\n",
        "    signal = signal.astype(np.float64)\n",
        "    signal /= gain\n",
        "    signal += offset\n",
        "    return signal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hecEtR58FUsF"
      },
      "source": [
        "## Step 2: Mask hot/dead pixel\n",
        "\n",
        "The dead pixels map is a map of the pixels that do not respond to light and, thus, can’t be accounted for any calculation. In all these frames the dead pixels are masked using python masked arrays. The bad pixels are thus masked but left uncorrected. Some methods can be used to correct bad-pixels but this task, if needed, is left to the participants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bCSK4l_E7lk"
      },
      "outputs": [],
      "source": [
        "def mask_hot_dead(signal, dead, dark):\n",
        "    hot = sigma_clip(\n",
        "        dark, sigma=5, maxiters=5\n",
        "    ).mask\n",
        "    hot = np.tile(hot, (signal.shape[0], 1, 1))\n",
        "    dead = np.tile(dead, (signal.shape[0], 1, 1))\n",
        "    signal = np.ma.masked_where(dead, signal)\n",
        "    signal = np.ma.masked_where(hot, signal)\n",
        "    return signal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEZtxRnEFdc8"
      },
      "source": [
        "## Step 2: linearity Correction¶\n",
        "**Non-linearity of pixels' response:**\n",
        "\n",
        "The non-linearity of the pixels’ response can be explained as capacitive leakage on the readout electronics of each pixel during the integration time. The number of electrons in the well is proportional to the number of photons that hit the pixel, with a quantum efficiency coefficient. However, the response of the pixel is not linear with the number of electrons in the well. This effect can be described by a polynomial function of the number of electrons actually in the well. The data is provided with calibration files linear_corr.parquet that are the coefficients of the inverse polynomial function and can be used to correct this non-linearity effect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTIRd9VNE7gC"
      },
      "outputs": [],
      "source": [
        "def apply_linear_corr(linear_corr,clean_signal):\n",
        "    linear_corr = np.flip(linear_corr, axis=0)\n",
        "    for x, y in itertools.product(\n",
        "                range(clean_signal.shape[1]), range(clean_signal.shape[2])\n",
        "            ):\n",
        "        poli = np.poly1d(linear_corr[:, x, y])\n",
        "        clean_signal[:, x, y] = poli(clean_signal[:, x, y])\n",
        "    return clean_signal\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqLWWdgfFzrq"
      },
      "source": [
        "## Step 3: dark current subtraction\n",
        "The data provided include calibration for dark current estimation, which can be used to pre-process the observations. Dark current represents a constant signal that accumulates in each pixel during the integration time, independent of the incoming light. To obtain the corrected image, the following conventional approach is applied: The data provided include calibration files such as dark frames or dead pixels' maps. They can be used to pre-process the observations. The dark frame is a map of the detector response to a very short exposure time, to correct for the dark current of the detector.\n",
        "\n",
        "image - dark\n",
        "×\n",
        "Δ\n",
        "t\n",
        "\n",
        "The corrected image is conventionally obtained via the following: where the dark current map is first corrected for the dead pixel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuTV6nEwE7Z1"
      },
      "outputs": [],
      "source": [
        "def clean_dark(signal, dead, dark, dt):\n",
        "\n",
        "    dark = np.ma.masked_where(dead, dark)\n",
        "    dark = np.tile(dark, (signal.shape[0], 1, 1))\n",
        "\n",
        "    signal -= dark* dt[:, np.newaxis, np.newaxis]\n",
        "    return signal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18EVxCIhGK6j"
      },
      "source": [
        "## Step 4: Get Correlated Double Sampling (CDS)\n",
        "The science frames are alternating between the start of the exposure and the end of the exposure. The lecture scheme is a ramp with a double sampling, called Correlated Double Sampling (CDS), the detector is read twice, once at the start of the exposure and once at the end of the exposure. The final CDS is the difference (End of exposure) - (Start of exposure)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbJwWxWHE7KU"
      },
      "outputs": [],
      "source": [
        "def get_cds(signal):\n",
        "    cds = signal[:,1::2,:,:] - signal[:,::2,:,:]\n",
        "    return cds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtaCx0kmGnJK"
      },
      "source": [
        "## Step 5: Time Binning\n",
        "This step is performed mianly to save space. Time series observations are binned together at specified frequency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlIJ4wu5Gnr_"
      },
      "outputs": [],
      "source": [
        "def bin_obs(cds_signal,binning):\n",
        "    cds_transposed = cds_signal.transpose(0,1,3,2)\n",
        "    cds_binned = np.zeros((cds_transposed.shape[0], cds_transposed.shape[1]//binning, cds_transposed.shape[2], cds_transposed.shape[3]), dtype=np.float64)\n",
        "    for i in range(cds_transposed.shape[1]//binning):\n",
        "        cds_binned[:,i,:,:] = np.sum(cds_transposed[:,i*binning:(i+1)*binning,:,:], axis=1)\n",
        "    return cds_binned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEXBn9DiGyOu"
      },
      "source": [
        "## Step 6: Flat Field Correction¶\n",
        "The flat field is a map of the detector response to uniform illumination, to correct for the pixel-to-pixel variations of the detector, for example the different quantum efficiencies of each pixel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3swx8BlXGy1u"
      },
      "outputs": [],
      "source": [
        "def correct_flat_field(flat,dead, signal):\n",
        "    flat = flat.transpose(1, 0)\n",
        "    dead = dead.transpose(1, 0)\n",
        "    flat = np.ma.masked_where(dead, flat)\n",
        "    flat = np.tile(flat, (signal.shape[0], 1, 1))\n",
        "    signal = signal / flat\n",
        "    return signal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb3l4ZY7HAzI"
      },
      "source": [
        "## Calibrating all training data\n",
        "\n",
        "You can choose to correct the non-linearity of the pixels' response, to apply flat field, dark and dead map or to leave the data unchanged. The observations are binned in time by group of 30 frames for AIRS and 360 frames for FGS1, to obtain a lighter data-cube, easier to use. The images are cut along the wavelength axis between pixels 39 and 321, so that the 282 pixels left in the wavelength dimension match the last 282 targets' points, from AIRS. The 283rd targets' point is the one for FGS1 that will be added later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBkAA-F1HBmm"
      },
      "outputs": [],
      "source": [
        "## we will start by getting the index of the training data:\n",
        "def get_index(files,CHUNKS_SIZE ):\n",
        "    index = []\n",
        "    for file in files :\n",
        "        file_name = file.split('/')[-1]\n",
        "        if file_name.split('_')[0] == 'AIRS-CH0' and file_name.split('_')[1] == 'signal.parquet':\n",
        "            file_index = os.path.basename(os.path.dirname(file))\n",
        "            index.append(int(file_index))\n",
        "    index = np.array(index)\n",
        "    index = np.sort(index)\n",
        "    index = np.array_split(index, len(index)//CHUNKS_SIZE)\n",
        "\n",
        "    return index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Fw91RToHTAY",
        "outputId": "7ceb8398-0130-4fc5-fe32-3cd879285c43"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 673/673 [4:56:43<00:00, 26.45s/it]\n"
          ]
        }
      ],
      "source": [
        "files = glob.glob(os.path.join(path_folder + 'train/', '*/*'))\n",
        "\n",
        "index = get_index(files[:],CHUNKS_SIZE)  ## 48 is hardcoded here but please feel free to remove it if you want to do it for the entire dataset\n",
        "\n",
        "train_adc_info = pd.read_csv(os.path.join(path_folder, 'train_adc_info.csv'))\n",
        "train_adc_info = train_adc_info.set_index('planet_id')\n",
        "axis_info = pd.read_parquet(os.path.join(path_folder,'axis_info.parquet'))\n",
        "DO_MASK = True\n",
        "DO_THE_NL_CORR = False\n",
        "DO_DARK = True\n",
        "DO_FLAT = True\n",
        "TIME_BINNING = True\n",
        "\n",
        "cut_inf, cut_sup = 39, 321\n",
        "l = cut_sup - cut_inf\n",
        "\n",
        "for n, index_chunk in enumerate(tqdm(index)):\n",
        "    AIRS_CH0_clean = np.zeros((CHUNKS_SIZE, 11250, 32, l))\n",
        "    FGS1_clean = np.zeros((CHUNKS_SIZE, 135000, 32, 32))\n",
        "\n",
        "    for i in range (CHUNKS_SIZE) :\n",
        "        df = pd.read_parquet(os.path.join(path_folder,f'train/{index_chunk[i]}/AIRS-CH0_signal.parquet'))\n",
        "        signal = df.values.astype(np.float64).reshape((df.shape[0], 32, 356))\n",
        "        gain = train_adc_info['AIRS-CH0_adc_gain'].loc[index_chunk[i]]\n",
        "        offset = train_adc_info['AIRS-CH0_adc_offset'].loc[index_chunk[i]]\n",
        "        signal = ADC_convert(signal, gain, offset)\n",
        "        dt_airs = axis_info['AIRS-CH0-integration_time'].dropna().values\n",
        "        dt_airs[1::2] += 0.1\n",
        "        chopped_signal = signal[:, :, cut_inf:cut_sup]\n",
        "        del signal, df\n",
        "\n",
        "        # CLEANING THE DATA: AIRS\n",
        "        flat = pd.read_parquet(os.path.join(path_folder,f'train/{index_chunk[i]}/AIRS-CH0_calibration/flat.parquet')).values.astype(np.float64).reshape((32, 356))[:, cut_inf:cut_sup]\n",
        "        dark = pd.read_parquet(os.path.join(path_folder,f'train/{index_chunk[i]}/AIRS-CH0_calibration/dark.parquet')).values.astype(np.float64).reshape((32, 356))[:, cut_inf:cut_sup]\n",
        "        dead_airs = pd.read_parquet(os.path.join(path_folder,f'train/{index_chunk[i]}/AIRS-CH0_calibration/dead.parquet')).values.astype(np.float64).reshape((32, 356))[:, cut_inf:cut_sup]\n",
        "        linear_corr = pd.read_parquet(os.path.join(path_folder,f'train/{index_chunk[i]}/AIRS-CH0_calibration/linear_corr.parquet')).values.astype(np.float64).reshape((6, 32, 356))[:, :, cut_inf:cut_sup]\n",
        "\n",
        "        if DO_MASK:\n",
        "            chopped_signal = mask_hot_dead(chopped_signal, dead_airs, dark)\n",
        "            AIRS_CH0_clean[i] = chopped_signal\n",
        "        else:\n",
        "            AIRS_CH0_clean[i] = chopped_signal\n",
        "\n",
        "        if DO_THE_NL_CORR:\n",
        "            linear_corr_signal = apply_linear_corr(linear_corr,AIRS_CH0_clean[i])\n",
        "            AIRS_CH0_clean[i,:, :, :] = linear_corr_signal\n",
        "        del linear_corr\n",
        "\n",
        "        if DO_DARK:\n",
        "            cleaned_signal = clean_dark(AIRS_CH0_clean[i], dead_airs, dark, dt_airs)\n",
        "            AIRS_CH0_clean[i] = cleaned_signal\n",
        "        else:\n",
        "            pass\n",
        "        del dark\n",
        "\n",
        "        df = pd.read_parquet(os.path.join(path_folder,f'train/{index_chunk[i]}/FGS1_signal.parquet'))\n",
        "        fgs_signal = df.values.astype(np.float64).reshape((df.shape[0], 32, 32))\n",
        "\n",
        "        FGS1_gain = train_adc_info['FGS1_adc_gain'].loc[index_chunk[i]]\n",
        "        FGS1_offset = train_adc_info['FGS1_adc_offset'].loc[index_chunk[i]]\n",
        "\n",
        "        fgs_signal = ADC_convert(fgs_signal, FGS1_gain, FGS1_offset)\n",
        "        dt_fgs1 = np.ones(len(fgs_signal))*0.1\n",
        "        dt_fgs1[1::2] += 0.1\n",
        "        chopped_FGS1 = fgs_signal\n",
        "        del fgs_signal, df\n",
        "\n",
        "        # CLEANING THE DATA: FGS1\n",
        "        flat = pd.read_parquet(os.path.join(path_folder,f'train/{index_chunk[i]}/FGS1_calibration/flat.parquet')).values.astype(np.float64).reshape((32, 32))\n",
        "        dark = pd.read_parquet(os.path.join(path_folder,f'train/{index_chunk[i]}/FGS1_calibration/dark.parquet')).values.astype(np.float64).reshape((32, 32))\n",
        "        dead_fgs1 = pd.read_parquet(os.path.join(path_folder,f'train/{index_chunk[i]}/FGS1_calibration/dead.parquet')).values.astype(np.float64).reshape((32, 32))\n",
        "        linear_corr = pd.read_parquet(os.path.join(path_folder,f'train/{index_chunk[i]}/FGS1_calibration/linear_corr.parquet')).values.astype(np.float64).reshape((6, 32, 32))\n",
        "\n",
        "        if DO_MASK:\n",
        "            chopped_FGS1 = mask_hot_dead(chopped_FGS1, dead_fgs1, dark)\n",
        "            FGS1_clean[i] = chopped_FGS1\n",
        "        else:\n",
        "            FGS1_clean[i] = chopped_FGS1\n",
        "\n",
        "        if DO_THE_NL_CORR:\n",
        "            linear_corr_signal = apply_linear_corr(linear_corr,FGS1_clean[i])\n",
        "            FGS1_clean[i,:, :, :] = linear_corr_signal\n",
        "        del linear_corr\n",
        "\n",
        "        if DO_DARK:\n",
        "            cleaned_signal = clean_dark(FGS1_clean[i], dead_fgs1, dark,dt_fgs1)\n",
        "            FGS1_clean[i] = cleaned_signal\n",
        "        else:\n",
        "            pass\n",
        "        del dark\n",
        "\n",
        "    # SAVE DATA AND FREE SPACE\n",
        "    AIRS_cds = get_cds(AIRS_CH0_clean)\n",
        "    FGS1_cds = get_cds(FGS1_clean)\n",
        "\n",
        "    del AIRS_CH0_clean, FGS1_clean\n",
        "\n",
        "    ## (Optional) Time Binning to reduce space\n",
        "    if TIME_BINNING:\n",
        "        AIRS_cds_binned = bin_obs(AIRS_cds,binning=30)\n",
        "        FGS1_cds_binned = bin_obs(FGS1_cds,binning=30*12)\n",
        "    else:\n",
        "        AIRS_cds = AIRS_cds.transpose(0,1,3,2) ## this is important to make it consistent for flat fielding, but you can always change it\n",
        "        AIRS_cds_binned = AIRS_cds\n",
        "        FGS1_cds = FGS1_cds.transpose(0,1,3,2)\n",
        "        FGS1_cds_binned = FGS1_cds\n",
        "\n",
        "    del AIRS_cds, FGS1_cds\n",
        "\n",
        "    for i in range (CHUNKS_SIZE):\n",
        "        flat_airs = pd.read_parquet(os.path.join(path_folder,f'train/{index_chunk[i]}/AIRS-CH0_calibration/flat.parquet')).values.astype(np.float64).reshape((32, 356))[:, cut_inf:cut_sup]\n",
        "        flat_fgs = pd.read_parquet(os.path.join(path_folder,f'train/{index_chunk[i]}/FGS1_calibration/flat.parquet')).values.astype(np.float64).reshape((32, 32))\n",
        "        if DO_FLAT:\n",
        "            corrected_AIRS_cds_binned = correct_flat_field(flat_airs,dead_airs, AIRS_cds_binned[i])\n",
        "            AIRS_cds_binned[i] = corrected_AIRS_cds_binned\n",
        "            corrected_FGS1_cds_binned = correct_flat_field(flat_fgs,dead_fgs1, FGS1_cds_binned[i])\n",
        "            FGS1_cds_binned[i] = corrected_FGS1_cds_binned\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    ## save data\n",
        "    np.save(os.path.join(path_out, 'AIRS_clean_train_{}.npy'.format(n)), AIRS_cds_binned)\n",
        "    np.save(os.path.join(path_out, 'FGS1_train_{}.npy'.format(n)), FGS1_cds_binned)\n",
        "    del AIRS_cds_binned\n",
        "    del FGS1_cds_binned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GvwY-lqiOUs2"
      },
      "outputs": [],
      "source": [
        "def load_data (file, chunk_size, nb_files) :\n",
        "    data0 = np.load(file + '_0.npy')\n",
        "    data_all = np.zeros((nb_files*chunk_size, data0.shape[1], data0.shape[2], data0.shape[3]))\n",
        "    data_all[:chunk_size] = data0\n",
        "    for i in range (1, nb_files) :\n",
        "        data_all[i*chunk_size:(i+1)*chunk_size] = np.load(file + '_{}.npy'.format(i))\n",
        "    return data_all\n",
        "\n",
        "data_train = load_data(path_out + 'AIRS_clean_train', CHUNKS_SIZE, len(index))\n",
        "data_train_FGS = load_data(path_out + 'FGS1_train', CHUNKS_SIZE, len(index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVaO8WfbHSqj"
      },
      "outputs": [],
      "source": [
        "np.save('/content/drive/MyDrive/NeurIPS/Data/' + 'data_train.npy', data_train)\n",
        "np.save('/content/drive/MyDrive/NeurIPS/Data/' + 'data_train_FGS.npy', data_train_FGS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwgKdV1wH7Kb"
      },
      "source": [
        "## Plots to confirm data preperation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVCpRarnHSeQ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('Shape of the training datasset: \\t')\n",
        "print('\\n For AIRS-CH0:', data_train.shape)\n",
        "print('\\n For FGS1:', data_train_FGS.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osfFA9XzIJa3"
      },
      "outputs": [],
      "source": [
        "plt.imshow(data_train_FGS[-1,50,:,:].T, aspect = 'auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKgXqc7xIMhg"
      },
      "outputs": [],
      "source": [
        "for i in range(len(data_train)) :\n",
        "    light_curve = data_train[i,:,:,:].sum(axis=(1,2))\n",
        "    plt.plot(light_curve/light_curve.mean(), '-', alpha=0.3)\n",
        "\n",
        "plt.xlabel('Time (frame index)')\n",
        "plt.ylabel('Normalized flux in the frame')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmlI2mmfITax"
      },
      "outputs": [],
      "source": [
        "from IPython.display import FileLink\n",
        "\n",
        "os.chdir(r'/content/drive/MyDrive/NeurIPS/Data/')\n",
        "FileLink(r'data_train_FGS.npy')\n",
        "#FileLink(r'data_train.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrsygnKgZ4Ls"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1lnH-AX6s7VbPlaLXFA4nLaftYiskDYeh",
      "authorship_tag": "ABX9TyM/gNKaZlA3/kkK9N+0KypW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
